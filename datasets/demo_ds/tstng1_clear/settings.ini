[TrainingData]
dataset = demo_ds
test_percent = 30
test_file = validation.csv


[Experiment]
experiment_title = tstng1
rubricator = subj
binary = false
threads = 3
n_folds = 2


[Preprocessing]
id = id_publ
title = title
text = ref_txt 
keywords = kw_list 
subj = SUBJ
ipv = IPV 
rgnti = RGNTI 
correct = eor
#
remove_stopwords = true
normalization = lemmatization
kw_delim = \
language = auto
batch_size = 5000


[WordEmbedding]
# Use existing model by file path
use_model =
# 50 by default
vector_dim = 50
pooling = sum

[Classification]
models = logistic_regression

[logistic_regression]
penalty = 
C = 
solver = 
fit_intercept = 
random_state = 
max_iter = 


[svm]
C =
kernel =
degree =
gamma =
coef0 =
random_state = 
max_iter = 


[perceptron]
hidden_layer_sizes =
solver = adam
activation =
alpha =
learning_rate =
learning_rate_init =
power_t =
random_state = 
max_iter = 


[knn]
n_neighbors =
weights =
p =


[decision_tree]
criterion =
splitter =
max_depth =
min_samples_split =
min_samples_leaf =
max_features =
random_state =


[random_forest]
n_estimators =
criterion =
max_depth =
min_samples_split =
min_samples_leaf =
max_features =
random_state =


[adaboost]
n_estimators =
learning_rate =
algorithm =
random_state =